{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c702d4-e84e-4602-98ec-71ec21eadce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a734ceb-44c4-4502-b1be-fb60b2fe80ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6638, 284)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('FINAL.csv', low_memory=False).drop(columns='Unnamed: 0')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a22bf3ec-529a-4637-a743-2fd4f2fadca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -8.0\n",
       "1    -7.0\n",
       "2   -13.0\n",
       "3    -2.0\n",
       "4     1.0\n",
       "5    43.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.Series([1,2,-4,7,10,52])\n",
    "shift = df.SPREAD.mean() - test.mean()\n",
    "round(test + shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a99fa826-407e-457c-98aa-5b0b20d6b252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RM = [col for col in df.columns if \"AVG\" in col or \"MOMENTUM\" in col]\n",
    "len(RM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0de1535e-c074-42a5-b6a0-044c648b601b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=RM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9970877b-8a40-4163-b63b-33bea99a7ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['H_WIN_PCT', 'A_WIN_PCT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06a905cb-e860-4be7-bcbc-84894eb5693a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lower_bound = -36.5\n",
    "upper_bound = 39.5\n",
    "\n",
    "# Cap the target variable (e.g., spread) within the defined bounds\n",
    "df[\"SPREAD_CAPPED\"] = df[\"SPREAD\"].clip(lower=lower_bound, upper=upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d3d411ad-6f6d-4d6d-b6ea-2eb2180a8ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6194, 285)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d309bd7-832e-42cc-9884-28e59638a6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [col for col in df.columns if \"AVG\" in col or \"MOMENTUM\" in col or \"WIN_PCT\" in col]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f907fa7-bf21-413e-8918-d54cab129cc3",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13a09641-7750-4ea4-85bf-eaf4541ff4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6194, 245)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df[features].corr().abs()\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "high_corr_features = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "\n",
    "df = df.drop(columns=high_corr_features)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "edf859ca-44ab-4ed4-a107-aeccc06078fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [col for col in df.columns if \"AVG\" in col or \"MOMENTUM\" in col or \"WIN_PCT\" in col]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee3a97e2-cc56-42c6-b555-f3548be06a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed978562-7c42-41e3-bf54-b36444101ffc",
   "metadata": {},
   "source": [
    "## Normalize numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92a4f2fc-0cde-4aeb-935a-da3f4040174e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zscores = np.abs(df[features].apply(zscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d82f5-7762-4ca8-83e6-b733d67127ea",
   "metadata": {},
   "source": [
    "## Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3140fe43-4af6-44fa-b653-1473b618ae25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[(zscores < 5).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c2ff312-3127-4538-ba3c-8b5052cd574a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN = df[df.SEASON_YEAR != '2024-25']\n",
    "TEST = df[df.SEASON_YEAR == '2024-25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c4b68fd-f8a4-4191-9538-6cb30904c744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.42165101334652"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN.shape[0] / (TRAIN.shape[0] + TEST.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c333b90-4ecb-45e6-ba37-4cbf46c2d334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5427, 105), (642, 105))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = TRAIN[features]\n",
    "X_test = TEST[features]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "755be936-1ba6-4e24-a3a3-5fee55f47b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5427, 642)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = TRAIN['SPREAD_CAPPED']\n",
    "y_test = TEST['SPREAD_CAPPED']\n",
    "\n",
    "y_train.shape[0], y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1f7c3f4-4726-49ad-baa4-2e8e250474b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a13f3e6-8477-4f60-8dae-f69ccf9175c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rfr \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabsolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m rfr\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=42, n_jobs=-1)\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d5c53cd7-ffbb-41d0-9a22-03442f77890c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "14fb7b49-aa6f-4aa7-864f-a308812bf06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6702ce1a-3c2c-4331-bc5e-0ec1ff1f8a28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 11.449283489096574\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f5252a-09fa-4aa5-a8f1-2f549af85bd0",
   "metadata": {},
   "source": [
    "## Further dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "46190a02-0be8-4f6e-aa72-3aa43358c96e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(rfr.feature_importances_, index=features)\n",
    "top_features = feature_importances.nlargest(50).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e082c148-e2c5-4cfd-9972-27b1e8d11492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train[top_features]\n",
    "X_test = X_test[top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d01077-e06f-4f69-adf1-d36ee5662dbe",
   "metadata": {},
   "source": [
    "## Baseline Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4829976d-ad09-4802-9bf1-3737b7cdfbef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cc517ab4-df3b-479b-b5ee-a2a85e7c4aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Ridge Regression MAE: 11.0996\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Baseline Ridge Regression MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4baa159-4a70-41dc-ae16-fff5e8469434",
   "metadata": {},
   "source": [
    "## Alpha parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1c2374ec-48a6-4cc0-acd3-712b9507a9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 10.0\n",
      "Tuned Ridge Regression MAE: 11.0752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "alpha_values = np.logspace(-3, 3, 7)  # [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "ridge_grid = GridSearchCV(Ridge(), {'alpha': alpha_values}, scoring='neg_mean_absolute_error', cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "best_alpha = ridge_grid.best_params_['alpha']\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "y_pred = best_ridge.predict(X_test)\n",
    "mae_tuned = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Tuned Ridge Regression MAE: {mae_tuned:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "658f8622-12e2-4363-90d6-e7d22ea87efa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined best alpha: 16.666666666666668\n",
      "Refined Ridge Regression MAE: 11.0705\n"
     ]
    }
   ],
   "source": [
    "fine_alpha_values = np.linspace(best_alpha / 2, best_alpha * 2, 10)\n",
    "\n",
    "ridge_grid_fine = GridSearchCV(Ridge(), {'alpha': fine_alpha_values}, scoring='neg_mean_absolute_error', cv=5)\n",
    "ridge_grid_fine.fit(X_train, y_train)\n",
    "\n",
    "best_alpha_fine = ridge_grid_fine.best_params_['alpha']\n",
    "y_pred_fine = ridge_grid_fine.best_estimator_.predict(X_test)\n",
    "mae_tuned_fine = mean_absolute_error(y_test, y_pred_fine)\n",
    "\n",
    "print(f\"Refined best alpha: {best_alpha_fine}\")\n",
    "print(f\"Refined Ridge Regression MAE: {mae_tuned_fine:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad3606a-e48b-4d1e-9674-56e271271d79",
   "metadata": {},
   "source": [
    "## Trying tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f7761e3-f56b-4dd8-9739-58b20153033f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9543232b-760b-4ac2-9d89-ea1b5154f132",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, objective=&#x27;reg:absoluteerror&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, objective=&#x27;reg:absoluteerror&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, objective='reg:absoluteerror', ...)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, objective=\"reg:absoluteerror\", random_state=42)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68866eb1-e02c-49ed-8bc8-49785ce6bd53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "907e6d2d-db74-42cd-bd3f-1176ade7fe85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MAE: 11.419951627780959\n"
     ]
    }
   ],
   "source": [
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(\"XGBoost MAE:\", mae_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a574e95f-47d2-49aa-921f-df151edbe2a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5184 candidates, totalling 25920 fits\n",
      "Tuned XGBoost MAE: 11.2259\n",
      "Best Params: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 1, 'reg_lambda': 10, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 1, 10],\n",
    "    'reg_lambda': [0, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(xgb, param_grid, scoring='neg_mean_absolute_error', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model and evaluate\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "mae_xgb_tuned = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"Tuned XGBoost MAE: {mae_xgb_tuned:.4f}\")\n",
    "print(f\"Best Params: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51702188-ca13-4371-8dea-a0c88c98143e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      3\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      6\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      7\u001b[0m mae_rf \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, y_pred_rf)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1321\u001b[0m         X,\n\u001b[0;32m   1322\u001b[0m         y,\n\u001b[0;32m   1323\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1324\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1325\u001b[0m     )\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=5, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MAE: {mae_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ab724-8744-4279-b49e-ff8e923f44de",
   "metadata": {},
   "source": [
    "## Back to linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25b06d44-a544-459d-850f-502b3ceb475b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_pipeline\n\u001b[1;32m----> 4\u001b[0m ridge_poly \u001b[38;5;241m=\u001b[39m make_pipeline(PolynomialFeatures(degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, include_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), Ridge(alpha\u001b[38;5;241m=\u001b[39mbest_alpha_fine))\n\u001b[0;32m      5\u001b[0m ridge_poly\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Predict and evaluate\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Ridge' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "ridge_poly = make_pipeline(PolynomialFeatures(degree=2, include_bias=False), Ridge(alpha=best_alpha_fine))\n",
    "ridge_poly.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_poly = ridge_poly.predict(X_test)\n",
    "mae_poly = mean_absolute_error(y_test, y_pred_poly)\n",
    "\n",
    "print(f\"Ridge with Polynomial Features MAE: {mae_poly:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "41397bb7-d894-40bb-a9ad-8156602a9e53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge with Interaction Terms MAE: 11.5551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "interaction = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "\n",
    "ridge_interaction = make_pipeline(interaction, Ridge(alpha=best_alpha_fine))\n",
    "ridge_interaction.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_interaction = ridge_interaction.predict(X_test)\n",
    "mae_interaction = mean_absolute_error(y_test, y_pred_interaction)\n",
    "\n",
    "print(f\"Ridge with Interaction Terms MAE: {mae_interaction:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d3dc3-0b37-4a91-899a-2ec86f804e24",
   "metadata": {},
   "source": [
    "## Optimizing Ridge Regression (SPREAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6d7fde33-f054-4052-9e9b-68ec7fee2e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "186ecb57-e639-4921-ada5-217a5ea3654d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.53493e-29): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "coef_magnitudes = np.abs(ridge.coef_)\n",
    "important_features = np.argsort(coef_magnitudes)[-100:]\n",
    "X_train_ridge = X_train.iloc[:, important_features]\n",
    "X_test_ridge = X_test.iloc[:, important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "354c0614-5c1c-4ea7-aef7-f731813076f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.53493e-29): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(Ridge(alpha=1.0), n_features_to_select=50)\n",
    "rfe.fit(X_train, y_train)\n",
    "X_train_rfe = X_train.iloc[:, rfe.support_]\n",
    "X_test_rfe = X_test.iloc[:, rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e741f172-d9ff-4a00-a31d-6130a80caeb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a6ae7268-0913-43a4-860f-06577e87f98a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_regression, k=50)\n",
    "X_train_kbest = selector.fit_transform(X_train, y_train)\n",
    "X_test_kbest = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0e69f221-4ad5-43ed-b36d-0d1f6e62385e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_sets = {\n",
    "    'Ridge Coefficients': (X_train_ridge, X_test_ridge),\n",
    "    'Recursive Feature Elimination': (X_train_rfe, X_test_rfe),\n",
    "    'Principal Component Analysis': (X_train_pca, X_test_pca),\n",
    "    'SelectKBest': (X_train_kbest, X_test_kbest),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "964123e1-289c-4acc-bd28-35e6faaae933",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Coefficients - Best Alpha: 10, MAE: 10.988955396021392\n",
      "Recursive Feature Elimination - Best Alpha: 10, MAE: 11.077957803403292\n",
      "Principal Component Analysis - Best Alpha: 0.01, MAE: 11.098252646040526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.2367e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.07423e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.38183e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.16574e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.2369e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.07442e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.38203e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.16593e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.23886e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.07635e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.38399e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.16788e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.25844e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.09567e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.40362e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.18742e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.45442e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.289e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.60002e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.38291e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\ral\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.99977e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest - Best Alpha: 1, MAE: 10.984891599972451\n"
     ]
    }
   ],
   "source": [
    "mae_results = {}\n",
    "\n",
    "for method, (X_train_fs, X_test_fs) in feature_sets.items():\n",
    "    param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "    grid_search = GridSearchCV(Ridge(), param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "    grid_search.fit(X_train_fs, y_train)\n",
    "    best_ridge = grid_search.best_estimator_\n",
    "    y_pred = best_ridge.predict(X_test_fs)\n",
    "    mae_results[method] = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"{method} - Best Alpha: {grid_search.best_params_['alpha']}, MAE: {mae_results[method]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "a4ebd2dc-8a8e-4678-bd81-0b171b271419",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Ridge Alpha: 0.35\n",
      "Final Mean Absolute Error: 10.98244153012179\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': [0.35]}\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train_kbest, y_train)\n",
    "\n",
    "# Best model\n",
    "best_ridge = grid_search.best_estimator_\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = best_ridge.predict(X_test_kbest)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Display final results\n",
    "best_ridge_params = grid_search.best_params_\n",
    "print(f\"Final Ridge Alpha: {best_ridge_params['alpha']}\")\n",
    "print(f\"Final Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19217a-2bba-4d8c-8ca5-06b6cc75452b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
